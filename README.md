# TP Intergiciel - Kafka

Auteurs : ***Maxence ZOLNIERUCK*** & ***Josue VIDREQUIN***

## Sommaire

- [TP Intergiciel - Kafka](#tp-intergiciel---kafka)
  - [Sommaire](#sommaire)
  - [Introduction](#introduction)
  - [Commandes](#commandes)
  - [D√©marrer les services](#d√©marrer-les-services)
    - [Topics Kafka](#topics-kafka)
    - [Base de donn√©es PostgreSQL](#base-de-donn√©es-postgresql)
    - [Consumers & Producers Kafa Java](#consumers--producers-kafa-java)
  - [Points techniques](#points-techniques)
    - [Architecture applicative](#architecture-applicative)
      - [Producer n¬∞1 : R√©cup√©ration des donn√©es](#producer-n1--r√©cup√©ration-des-donn√©es)
      - [Consumer n¬∞1 : Stockage en base de donn√©es](#consumer-n1--stockage-en-base-de-donn√©es)
      - [Pr2Cs3](#pr2cs3)
      - [Cs2Pr3](#cs2pr3)
    - [Base de donn√©es](#base-de-donn√©es)
    - [Format des donn√©es](#format-des-donn√©es)
    - [Reception des resultats](#reception-des-resultats)

## Introduction

Ce d√©p√¥t GitHub fait office de rendu de projet dans le cadre du module Intergiciel √† l'INSA Hauts-de-France. Le but de ce projet est d'utiliser un bus de messages Kafka afin de faire communiquer plusieurs projets Java. L'application finale est utilisable via ligne de commandes et restitue plusieurs informations et statistiques calcul√©s gr√¢ce aux donn√©es de l'API publique <https://api.covid19api.com>.

Parmis les valeurs que nous restituons, nous retrouvons : le nombre total de cas confirm√©s, le nombre total de personnes d√©c√©d√©es, le nombre de nouveaux cas, le nombre de nouveaux d√©c√®s et enfin, le nombre de personnes r√©tablies. Ces donn√©es sont regroup√©es soit par pays, soit √† l'international avec des valeurs cumul√©es.

Toutes les donn√©es (sauf pour l'export) sont retourn√©es √† l'utilisateur au format JSON.

## Commandes

Voici les commandes support√©es par l'application :

- **help** : affiche les commandes disponibles.
- **get_global_values** : affiche les valeurs cumul√©es de tous les pays.
- **get_country_values V_PAYS** : affiche les donn√©es sp√©cifiques √† un pays. Exemple : V_PAYS=FR
- **get_confirmed_avg** : affiche une moyenne des cas confirm√©s.
- **get_deaths_avg** : affiche une moyenne des d√©c√®s.
- **get_countries_deaths_percent** : affiche le pourcentage de d√©c√®s par rapport aux cas confirm√©s par pays.
- **export** : affiche une extraction de la base de donn√©es au format XML.

Ci dessous, le r√©sultat de l'ex√©cution de la commande **help** :

![Commande Help](./Images/commande_help.png)

Un exemple de retour de commande avec **get_country_values FR** :

![Exemple get_countr_values](./Images/get_country_values-exemple.png)

## D√©marrer les services

Le projet est compos√© grossi√®rement de trois blocs :

1. Les topics Kafka
2. La base de donn√©es PostgreSQL
3. Les projets Java (Consumers & Producers Kafka)

Nous allons voir comment lancer le projet, pas √† pas. Il y a √† votre disposition des [Scripts](./Scripts) qui vous aideront dans ce processus.

Il est important de suivre les √©tapes dans l'ordre car il y a une certaine logique dans le branchement des diff√©rentes parties.

### Topics Kafka

Tout d'abord, il vous faut avoir install√© Kafka sur votre PC. Pour notre part, nous l'avons install√© sur Windows 11 sur `C:\Kafka`.

Si vous rencontrez des probl√®mes pour l'installation de Kafka, nous vous recommandons ce tutoriel que nous avons suivi pour ce TP : <https://www.geeksforgeeks.org/how-to-install-and-run-apache-kafka-on-windows/>

Une fois Kafka install√©, vous pouvez utiliser le script [demarrage_kafka_zookeeper.bat](./Scripts/demarrage_kafka_zookeeper.bat) afin de d√©marrer les services `Kafka` et `Zookeeper`.

Maintenant, nous allons passer √† la cr√©ation des topics qui seront utilis√©s par les applications Java. Pour cela, le script [creation_topics_kafka.bat](./Scripts/creation_topics_kafka.bat) a √©t√© cr√©√©.

Finalement, apr√®s avoir d√©marr√© Kafka et cr√©√© les topics, nous pouvons tester le bon fonctionnement des scripts avec la commande :

> C:\Kafka\bin\windows\kafka-topics.bat --bootstrap-server localhost:9092 --describe --topic TOPIC_NAME

O√π TOPIC_NAME peut prendre les valeurs : topic1, topic2 et topic3.

Bien, nous avons pass√© la premi√®re √©tape, int√©ressons nous maintenant √† la base de donn√©es PostgreSQL.

### Base de donn√©es PostgreSQL

Pour ce projet nous utilisons une base de donn√©es PostgreSQL car elle permet de stocker des valeurs au format JSON directement. Chose tr√®s utile pour nous qui utilisons une API publique nous retournant les valeurs au format JSON. De ce fait, apr√®s quelques traitements, nous pouvons directement stocker le resultat de l'appel dans la base de donn√©es.

Nous avons utilis√© une image docker pour heberger notre base de donn√©es. Vous pouvez retrouver le [docker-compose.yml](docker-compose.yml) a la racine de ce rep√©rtoire pour lancer vous m√™me l'image docker.

La base de donn√©es sera accessible via l'adresse `http://localhost:5432/HOPSIIA`.

Ensuite, vous pouvez utiliser l'outil [pgAdmin](https://www.pgadmin.org/) mis √† disposition par PostgreSQL afin d'administrer vos bases de donn√©es.

![pgAdmin DB](./Images/pgadmin_db.png)

Maintenant que la base de donn√©es a √©t√© cr√©√©e, il faut instancier la table qui accueillera les donn√©es de l'API Covid-19. Pour cela, vous avez √† votre disposition le script [creation_table_postgres.sql](./Scripts/creation_table_postgres.sql) dans ce d√©pot pour la cr√©ation de la table **covid**.

Ensuite, il faut initialiser la table avec un enregistrement vide. Pour cela, ex√©cutez la requ√™te qui se trouve dans [initialiser_table_postgres.sql](./Scripts/initialiser_table_postgres.sql).

Le second point de ce projet est pr√™t. Cette base de donn√©es sera aliment√©e gr√¢ce √† deux projets Java : Cs1 (Consumer 1) et Pr1 (Producer 1) que nous allons aborder d√®s maintenant.

### Consumers & Producers Kafa Java

Les modules Java sont accessibles dans le dossier [Sources](./Sources/).

Il faut imp√©rativement d√©marrer les modules dans cet ordre :

1. Producer n¬∞1 ([Pr1](./Sources/pr1/))
2. Consumer n¬∞1 ([Cs1](./Sources/cs1/))
3. Consumer n¬∞2 & Producer n¬∞3 ([Cs2Pr3](./Sources/cs2pr3/))
4. Producer n¬∞2 & Consumer n¬∞3 ([Pr2Cs3](./Sources/pr2cs3/))

Vous pouvez les importer dans le workspace de votre IDE favori (pour nous c'est [Eclipse](https://www.eclipse.org/ide/) üíú) et les lancer dans l'ordre d√©crit ci-dessus.

Tous les projets ont une classe portant comme nom `XXX`MainClass o√π `XXX` est le nom du projet. Par exemple : [Pr1MainClass.java](./Sources/pr1/src/main/java/pr1/Pr1MainClass.java). Ce sera ces classes qu'il faut d√©marrer pour lancer le module.

## Points techniques

### Architecture applicative

Les consumers (Cs) et Producers (Pr) sont des applications Kafka permetant d'√©crire dans un topic pour un Pr et de lire les messages pour un Cs. Dans notre projet, il y a 4 "briques" :

- Pr1 : Lit les messages de l'API Covid
- Cs1 : Mets √† jour la base de donn√©es
- Pr2Cs3 : L'invit√© de commande utilis√© pour saisir les commandes
- Cs2Pr3 : Communique avec la base de donn√©es et effectue des traitements sp√©cifiques √† la demande utilisateur re√ßue

Ces briques Kafka communiquent entre elles via les topics cr√©√©s pr√©c√©demment √† la section [Topics Kafa](#topics-kafka).

Pour un peu plus de claret√©, voici un sch√©ma de l'architecture applicative de notre projet :

![Architecture Applicative](./Images/architecture_applicative.png)

#### Producer n¬∞1 : R√©cup√©ration des donn√©es

Ce projet fait un appel automatis√© toutes les 30 minutes via la librairie [Quartz Scheduler](http://www.quartz-scheduler.org/) √† l'[API Covid-19](https://api.covid19api.com). A chaque fois que le projet r√©cup√®re les donn√©es de l'API, nous effectuons un l√©ger traitement pour √©purer le JSON en supprimant certains champs qui ne nous int√©ressent pas ici. Ensuite, le JSON nouvellement cr√©√© est envoy√© dans le topic n¬∞1.

![Partie Producer n¬∞1](./Images/partie_pr1.png)

#### Consumer n¬∞1 : Stockage en base de donn√©es

Du c√¥t√© Consumer n¬∞1, le module est en attente constante de nouveaux messages √† lire dans le topic n¬∞1. Quand un message est d√©tect√©, le module en r√©cup√®re le contenu et effectue une connexion √† la base de donn√©es pour envoyer la mise √† jour des donn√©es.

![Partie Consumer n¬∞1](./Images/partie_cs1.png)

#### Pr2Cs3

Le module le plus lourd est celui-ci √©tant donn√© qu'il embarque √† la fois : une partie consumer, une partie producer et une partie invit√© de commande pour que l'utilisateur saisisse ses requ√™tes. Cependant, son fonctionnement est assez simple. Apr√®s avoir demand√© √† l'utilisateur la commande qu'il souhaite ex√©cuter, le module v√©rifie que celle-ci est bien valide et qu'elle pourra √™tre ex√©cut√©e c√¥t√© [Cs2Pr3](#cs2pr3) sans aucun soucis. Ensuite, la commande est envoy√©e via le topic n¬∞2 et sera ex√©cut√©e par l'autre module. Lorsque la requ√™te aura √©t√© ex√©cut√©e, notre module r√©cup√®rera le r√©sultat dans le topic n¬∞3 afin de l'afficher √† l'√©cran pour l'utilisateur.

![Partie Producer n¬∞2 & Consumer n¬∞3](./Images/partie_pr2cs3.png)

#### Cs2Pr3

Ce module fait office d'interface avec la base de donn√©e et de brique de calcul. En effet, ce module lit des commandes utilisateurs √† travers le topic n¬∞2 qu'il transcode en requ√™te SQL pour int√©rroger la base de donn√©es. Une fois les donn√©es re√ßues, un enchainement de calculs est ex√©cut√© pour r√©pondre √† la demande utilisateur. Enfin, ce resultat est communiqu√© au module appelant via le topic n¬∞3.

![Partie Consumer n¬∞2 & Producer n¬∞3](./Images/partie_cs2pr3.png)

### Base de donn√©es

### Format des donn√©es

### Reception des resultats
